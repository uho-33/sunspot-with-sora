{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总亮度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化方法：\n",
    "- 假设服从平方反比，标准到 $1AU$ 的结果\n",
    "- 随机采样计算得到平均值 $m$ ，标准差 $sigma$\n",
    "- 标准化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HDF5 file: data\\processed\\Ic_720s_normalize_distance\\hmi.ic_720s.20200601_000000_TAI.3.continuum_nd.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "handle is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Process files in parallel\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# Submit all files for processing\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     futures \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_fits_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfits_files\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(fits_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[19], line 67\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Process files in parallel\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# Submit all files for processing\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 67\u001b[0m         \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_fits_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m fits_files\n\u001b[0;32m     69\u001b[0m     ]\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(fits_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\concurrent\\futures\\process.py:808\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread_wakeup\u001b[38;5;241m.\u001b[39mwakeup()\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_to_dynamically_spawn_children:\n\u001b[1;32m--> 808\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adjust_process_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_executor_manager_thread()\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\concurrent\\futures\\process.py:767\u001b[0m, in \u001b[0;36mProcessPoolExecutor._adjust_process_count\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    759\u001b[0m process_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processes)\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_count \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_workers:\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;66;03m# Assertion disabled as this codepath is also used to replace a\u001b[39;00m\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;66;03m# worker that unexpectedly dies, even when using the 'fork' start\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;66;03m# we know a thread is running (self._executor_manager_thread).\u001b[39;00m\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m#assert self._safe_to_dynamically_spawn_children or not self._executor_manager_thread, 'https://github.com/python/cpython/issues/90622'\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawn_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\concurrent\\futures\\process.py:785\u001b[0m, in \u001b[0;36mProcessPoolExecutor._spawn_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_spawn_process\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    778\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mp_context\u001b[38;5;241m.\u001b[39mProcess(\n\u001b[0;32m    779\u001b[0m         target\u001b[38;5;241m=\u001b[39m_process_worker,\n\u001b[0;32m    780\u001b[0m         args\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_queue,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initargs,\n\u001b[0;32m    784\u001b[0m               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_tasks_per_child))\n\u001b[1;32m--> 785\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processes[p\u001b[38;5;241m.\u001b[39mpid] \u001b[38;5;241m=\u001b[39m p\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py:975\u001b[0m, in \u001b[0;36mreduce_pipe_connection\u001b[1;34m(conn)\u001b[0m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce_pipe_connection\u001b[39m(conn):\n\u001b[0;32m    973\u001b[0m     access \u001b[38;5;241m=\u001b[39m ((_winapi\u001b[38;5;241m.\u001b[39mFILE_GENERIC_READ \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mreadable \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m|\u001b[39m\n\u001b[0;32m    974\u001b[0m               (_winapi\u001b[38;5;241m.\u001b[39mFILE_GENERIC_WRITE \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mwritable \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m--> 975\u001b[0m     dh \u001b[38;5;241m=\u001b[39m reduction\u001b[38;5;241m.\u001b[39mDupHandle(\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, access)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rebuild_pipe_connection, (dh, conn\u001b[38;5;241m.\u001b[39mreadable, conn\u001b[38;5;241m.\u001b[39mwritable)\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py:171\u001b[0m, in \u001b[0;36m_ConnectionBase.fileno\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfileno\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"File descriptor or handle of the connection\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_closed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py:137\u001b[0m, in \u001b[0;36m_ConnectionBase._check_closed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_closed\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandle is closed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: handle is closed"
     ]
    }
   ],
   "source": [
    "import astropy.units as u\n",
    "import sunpy.map\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from glob import glob\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import gc  # Add garbage collection\n",
    "import time  # For timing stats\n",
    "\n",
    "# Configure logging\n",
    "log_dir = \"Data-process\"\n",
    "log_file = Path(log_dir) / \"processing.log\"\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def normalize_distance(data_map):\n",
    "    \"\"\"Normalize the data based on distance to Sun in AU.\"\"\"\n",
    "    data_out = data_map.data * (data_map.dsun.to(u.AU)/(1 * u.AU).value)**2\n",
    "    return data_out\n",
    "\n",
    "def save_as_hdf5(data, output_path):\n",
    "    \"\"\"Save normalized data as HDF5 file.\"\"\"\n",
    "    with h5py.File(output_path, 'w') as hf:\n",
    "        hf.create_dataset('data', data=data, compression=\"gzip\", compression_opts=9)\n",
    "\n",
    "def is_processed(input_path, output_dir):\n",
    "    \"\"\"Check if a file has already been processed.\"\"\"\n",
    "    base_name = Path(input_path).stem\n",
    "    hdf5_path = Path(output_dir) / f\"{base_name}_nd.h5\"\n",
    "    return hdf5_path.exists()\n",
    "\n",
    "def get_output_path(input_path, output_dir):\n",
    "    \"\"\"Get the output HDF5 path for a given input file.\"\"\"\n",
    "    base_name = Path(input_path).stem\n",
    "    return Path(output_dir) / f\"{base_name}_nd.h5\"\n",
    "\n",
    "def process_fits_file(input_path, output_dir, allow_errors=False):\n",
    "    \"\"\"Process a FITS file and save normalized data as HDF5.\"\"\"\n",
    "    try:\n",
    "        # Load and process data\n",
    "        data_map = sunpy.map.Map(input_path)\n",
    "        normalized_data = normalize_distance(data_map)\n",
    "        \n",
    "        # Generate output filename and save\n",
    "        hdf5_path = get_output_path(input_path, output_dir)\n",
    "        save_as_hdf5(normalized_data, hdf5_path)\n",
    "        \n",
    "        # Explicitly clear references to free memory\n",
    "        del data_map\n",
    "        del normalized_data\n",
    "        gc.collect()  # Force garbage collection\n",
    "        \n",
    "        # logging.info(f\"Saved HDF5 file: {hdf5_path}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing file {input_path}: {e}\")\n",
    "        if not allow_errors:\n",
    "            raise\n",
    "        return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    os.chdir(r\"E:\\study-and-research\\sunspot-sith-sora\")\n",
    "\n",
    "    # Get all FITS files in the input directory\n",
    "    input_dir = Path(r\"data\\origin\\Ic_720s\")\n",
    "    output_dir = Path(r\"data\\processed\\Ic_720s_normalize_distance\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Pre-filter files to process\n",
    "    fits_files = list(input_dir.glob(\"*.fits\"))\n",
    "    total_files = len(fits_files)\n",
    "    \n",
    "    # Pre-check which files need processing\n",
    "    files_to_process = []\n",
    "    skipped_files = 0\n",
    "    \n",
    "    logging.info(f\"Checking {total_files} files for processing status...\")\n",
    "    \n",
    "    for file in fits_files:\n",
    "        if is_processed(file, output_dir):\n",
    "            skipped_files += 1\n",
    "        else:\n",
    "            files_to_process.append(file)\n",
    "    \n",
    "    need_processing = len(files_to_process)\n",
    "    logging.info(f\"Found {need_processing} files to process, {skipped_files} already processed\")\n",
    "    \n",
    "    # Counter for processed files\n",
    "    processed_files = 0\n",
    "    error_files = 0\n",
    "\n",
    "    # Process files in parallel with optimal workers\n",
    "    max_workers = 10\n",
    "    \n",
    "    if files_to_process:\n",
    "        logging.info(f\"Starting processing with {max_workers} workers\")\n",
    "        with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Process files in batches to prevent memory buildup\n",
    "            batch_size = 10\n",
    "            for i in range(0, len(files_to_process), batch_size):\n",
    "                batch = files_to_process[i:i+batch_size]\n",
    "                # logging.info(f\"Processing batch {i//batch_size + 1} of {(len(files_to_process)-1)//batch_size + 1} ({len(batch)} files)\")\n",
    "                \n",
    "                # Submit batch for processing\n",
    "                futures = [\n",
    "                    executor.submit(process_fits_file, str(file), output_dir, True)\n",
    "                    for file in batch\n",
    "                ]\n",
    "                \n",
    "                # Process results\n",
    "                for future in futures:\n",
    "                    try:\n",
    "                        result = future.result()\n",
    "                        if result is True:\n",
    "                            processed_files += 1\n",
    "                        else:\n",
    "                            error_files += 1\n",
    "                    except Exception as e:\n",
    "                        error_files += 1\n",
    "                        logging.error(f\"Failed to process a file: {e}\")\n",
    "                \n",
    "                # Ensure memory is freed between batches\n",
    "                gc.collect()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    logging.info(f\"Processing complete in {elapsed_time:.2f} seconds:\")\n",
    "    logging.info(f\"Total files: {total_files}\")\n",
    "    logging.info(f\"Already processed (skipped): {skipped_files}\")\n",
    "    logging.info(f\"Successfully processed: {processed_files}\")\n",
    "    logging.info(f\"Failed to process: {error_files}\")\n",
    "    \n",
    "    if processed_files > 0:\n",
    "        logging.info(f\"Average processing time per file: {elapsed_time/processed_files:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化方法：\n",
    "- 随机化计算有效数据点数的平均值 $n$\n",
    "- 计算标准化系数：$m_f=m/n$ , $sigma_f=sigma/\\sqrt{n}$\n",
    "- 选取 $4 sigma$ 内结果映射到 $[0,255]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "import sunpy.map\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# 消除距离影响\n",
    "def normize_distance(data_in):\n",
    "    data_out = data_in * (data_in.dsun.to(u.AU).value/(1 * u.AU))**2\n",
    "    return data_out\n",
    "\n",
    "# 将数据映射到[0, 255]\n",
    "def arr2img(data_in, sigma, m):\n",
    "    nan_replaced_data = np.nan_to_num(data_in, nan=0)\n",
    "\n",
    "    fig_arr = np.clip((nan_replaced_data - (m - 2 * sigma)) / (4 * sigma) * 255, 0, 255)\n",
    "\n",
    "    figure = Image.fromarray(fig_arr)\n",
    "    return figure\n",
    "\n",
    "data_in = sunpy.map.Map(\n",
    "    \"fig/Ic_720s/hmi.ic_720s.20230601_000000_TAI.3.continuum.fits\"\n",
    ").data\n",
    "data_out = arr2img(norm_distance(data_in))\n",
    "\n",
    "\n",
    "plt.imshow(t_data2)\n",
    "\n",
    "t_data2.convert(\"RGB\").save(\"output_image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: 验证 DN/s 是否服从平方反比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "import sunpy.map\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_in = sunpy.map.Map(\n",
    "    \"../data/Ic_nolimbdark_720s\\hmi.ic_nolimbdark_720s.20211101_120000_TAI.3.continuum.fits\"\n",
    ")\n",
    "data_in_2 = sunpy.map.Map(\n",
    "    \"../data/Ic_720s/hmi.ic_720s.20200601_120000_TAI.3.continuum.fits\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_in.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DN/s'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in.meta.get('BUNIT')\n",
    "data_in_2.meta.get('BUNIT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
