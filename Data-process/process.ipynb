{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总亮度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化方法：\n",
    "- 假设服从平方反比，标准到 $1AU$ 的结果\n",
    "- 所有数据计算得到平均值 $m$ ，标准差 $sigma$\n",
    "- 标准化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HDF5 file: data\\processed\\Ic_720s_normalize_distance\\hmi.ic_720s.20200601_000000_TAI.3.continuum_nd.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"d:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "handle is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Process files in parallel\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# Submit all files for processing\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     futures \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_fits_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfits_files\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(fits_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[19], line 67\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Process files in parallel\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# Submit all files for processing\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 67\u001b[0m         \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_fits_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m fits_files\n\u001b[0;32m     69\u001b[0m     ]\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(fits_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\concurrent\\futures\\process.py:808\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread_wakeup\u001b[38;5;241m.\u001b[39mwakeup()\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_to_dynamically_spawn_children:\n\u001b[1;32m--> 808\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adjust_process_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_executor_manager_thread()\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\concurrent\\futures\\process.py:767\u001b[0m, in \u001b[0;36mProcessPoolExecutor._adjust_process_count\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    759\u001b[0m process_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processes)\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_count \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_workers:\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;66;03m# Assertion disabled as this codepath is also used to replace a\u001b[39;00m\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;66;03m# worker that unexpectedly dies, even when using the 'fork' start\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;66;03m# we know a thread is running (self._executor_manager_thread).\u001b[39;00m\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m#assert self._safe_to_dynamically_spawn_children or not self._executor_manager_thread, 'https://github.com/python/cpython/issues/90622'\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawn_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\concurrent\\futures\\process.py:785\u001b[0m, in \u001b[0;36mProcessPoolExecutor._spawn_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_spawn_process\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    778\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mp_context\u001b[38;5;241m.\u001b[39mProcess(\n\u001b[0;32m    779\u001b[0m         target\u001b[38;5;241m=\u001b[39m_process_worker,\n\u001b[0;32m    780\u001b[0m         args\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_queue,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initargs,\n\u001b[0;32m    784\u001b[0m               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_tasks_per_child))\n\u001b[1;32m--> 785\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processes[p\u001b[38;5;241m.\u001b[39mpid] \u001b[38;5;241m=\u001b[39m p\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py:975\u001b[0m, in \u001b[0;36mreduce_pipe_connection\u001b[1;34m(conn)\u001b[0m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce_pipe_connection\u001b[39m(conn):\n\u001b[0;32m    973\u001b[0m     access \u001b[38;5;241m=\u001b[39m ((_winapi\u001b[38;5;241m.\u001b[39mFILE_GENERIC_READ \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mreadable \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m|\u001b[39m\n\u001b[0;32m    974\u001b[0m               (_winapi\u001b[38;5;241m.\u001b[39mFILE_GENERIC_WRITE \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mwritable \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m--> 975\u001b[0m     dh \u001b[38;5;241m=\u001b[39m reduction\u001b[38;5;241m.\u001b[39mDupHandle(\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, access)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rebuild_pipe_connection, (dh, conn\u001b[38;5;241m.\u001b[39mreadable, conn\u001b[38;5;241m.\u001b[39mwritable)\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py:171\u001b[0m, in \u001b[0;36m_ConnectionBase.fileno\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfileno\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"File descriptor or handle of the connection\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_closed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\multiprocessing\\connection.py:137\u001b[0m, in \u001b[0;36m_ConnectionBase._check_closed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_closed\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandle is closed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: handle is closed"
     ]
    }
   ],
   "source": [
    "import astropy.units as u\n",
    "import sunpy.map\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from glob import glob\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import gc  # Add garbage collection\n",
    "import time  # For timing stats\n",
    "\n",
    "# Configure logging\n",
    "log_dir = \"Data-process\"\n",
    "log_file = Path(log_dir) / \"processing.log\"\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def normalize_distance(data_map):\n",
    "    \"\"\"Normalize the data based on distance to Sun in AU.\"\"\"\n",
    "    data_out = data_map.data * (data_map.dsun.to(u.AU)/(1 * u.AU).value)**2\n",
    "    return data_out\n",
    "\n",
    "def save_as_hdf5(data, output_path):\n",
    "    \"\"\"Save normalized data as HDF5 file.\"\"\"\n",
    "    with h5py.File(output_path, 'w') as hf:\n",
    "        hf.create_dataset('data', data=data, compression=\"gzip\", compression_opts=9)\n",
    "\n",
    "def is_processed(input_path, output_dir):\n",
    "    \"\"\"Check if a file has already been processed.\"\"\"\n",
    "    base_name = Path(input_path).stem\n",
    "    hdf5_path = Path(output_dir) / f\"{base_name}_nd.h5\"\n",
    "    return hdf5_path.exists()\n",
    "\n",
    "def get_output_path(input_path, output_dir):\n",
    "    \"\"\"Get the output HDF5 path for a given input file.\"\"\"\n",
    "    base_name = Path(input_path).stem\n",
    "    return Path(output_dir) / f\"{base_name}_nd.h5\"\n",
    "\n",
    "def process_fits_file(input_path, output_dir, allow_errors=False):\n",
    "    \"\"\"Process a FITS file and save normalized data as HDF5.\"\"\"\n",
    "    try:\n",
    "        # Load and process data\n",
    "        data_map = sunpy.map.Map(input_path)\n",
    "        normalized_data = normalize_distance(data_map)\n",
    "        \n",
    "        # Generate output filename and save\n",
    "        hdf5_path = get_output_path(input_path, output_dir)\n",
    "        save_as_hdf5(normalized_data, hdf5_path)\n",
    "        \n",
    "        # Explicitly clear references to free memory\n",
    "        del data_map\n",
    "        del normalized_data\n",
    "        gc.collect()  # Force garbage collection\n",
    "        \n",
    "        # logging.info(f\"Saved HDF5 file: {hdf5_path}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing file {input_path}: {e}\")\n",
    "        if not allow_errors:\n",
    "            raise\n",
    "        return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    os.chdir(r\"E:\\study-and-research\\sunspot-sith-sora\")\n",
    "\n",
    "    # Get all FITS files in the input directory\n",
    "    input_dir = Path(r\"data\\origin\\Ic_720s\")\n",
    "    output_dir = Path(r\"data\\processed\\Ic_720s_normalize_distance\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Pre-filter files to process\n",
    "    fits_files = list(input_dir.glob(\"*.fits\"))\n",
    "    total_files = len(fits_files)\n",
    "    \n",
    "    # Pre-check which files need processing\n",
    "    files_to_process = []\n",
    "    skipped_files = 0\n",
    "    \n",
    "    logging.info(f\"Checking {total_files} files for processing status...\")\n",
    "    \n",
    "    for file in fits_files:\n",
    "        if is_processed(file, output_dir):\n",
    "            skipped_files += 1\n",
    "        else:\n",
    "            files_to_process.append(file)\n",
    "    \n",
    "    need_processing = len(files_to_process)\n",
    "    logging.info(f\"Found {need_processing} files to process, {skipped_files} already processed\")\n",
    "    \n",
    "    # Counter for processed files\n",
    "    processed_files = 0\n",
    "    error_files = 0\n",
    "\n",
    "    # Process files in parallel with optimal workers\n",
    "    max_workers = 10\n",
    "    \n",
    "    if files_to_process:\n",
    "        logging.info(f\"Starting processing with {max_workers} workers\")\n",
    "        with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Process files in batches to prevent memory buildup\n",
    "            batch_size = 10\n",
    "            for i in range(0, len(files_to_process), batch_size):\n",
    "                batch = files_to_process[i:i+batch_size]\n",
    "                # logging.info(f\"Processing batch {i//batch_size + 1} of {(len(files_to_process)-1)//batch_size + 1} ({len(batch)} files)\")\n",
    "                \n",
    "                # Submit batch for processing\n",
    "                futures = [\n",
    "                    executor.submit(process_fits_file, str(file), output_dir, True)\n",
    "                    for file in batch\n",
    "                ]\n",
    "                \n",
    "                # Process results\n",
    "                for future in futures:\n",
    "                    try:\n",
    "                        result = future.result()\n",
    "                        if result is True:\n",
    "                            processed_files += 1\n",
    "                        else:\n",
    "                            error_files += 1\n",
    "                    except Exception as e:\n",
    "                        error_files += 1\n",
    "                        logging.error(f\"Failed to process a file: {e}\")\n",
    "                \n",
    "                # Ensure memory is freed between batches\n",
    "                gc.collect()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    logging.info(f\"Processing complete in {elapsed_time:.2f} seconds:\")\n",
    "    logging.info(f\"Total files: {total_files}\")\n",
    "    logging.info(f\"Already processed (skipped): {skipped_files}\")\n",
    "    logging.info(f\"Successfully processed: {processed_files}\")\n",
    "    logging.info(f\"Failed to process: {error_files}\")\n",
    "    \n",
    "    if processed_files > 0:\n",
    "        logging.info(f\"Average processing time per file: {elapsed_time/processed_files:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2160 h5 files\n",
      "Calculating total brightness for each file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad6b91e1bba45c89b318e676ce55caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m hf:\n\u001b[1;32m---> 26\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mhf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     27\u001b[0m         brightness \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnansum(data)\n\u001b[0;32m     28\u001b[0m         brightness_values\u001b[38;5;241m.\u001b[39mappend((file_path\u001b[38;5;241m.\u001b[39mname, brightness))\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\software\\Anaconda\\Lib\\site-packages\\h5py\\_hl\\dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, args, new_dtype)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_reader\u001b[38;5;241m.\u001b[39mread(args)\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "import datetime\n",
    "import concurrent.futures\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "os.chdir(r\"E:\\study-and-research\\sunspot-with-sora\")\n",
    "\n",
    "# Directory containing the processed h5 files\n",
    "data_dir = Path(\"data/processed/Ic_720s_normalize_distance\")\n",
    "\n",
    "# Get all h5 files\n",
    "h5_files = list(data_dir.glob(\"*.h5\"))\n",
    "print(f\"Found {len(h5_files)} h5 files\")\n",
    "\n",
    "def extract_timestamp(filename):\n",
    "    \"\"\"\n",
    "    Extract timestamp from the filename.\n",
    "    Assumes filename format contains date/time information.\n",
    "    Modify the regex pattern based on your actual filename format.\n",
    "    \"\"\"\n",
    "    # Example pattern: looking for something like YYYY-MM-DD_HH-MM-SS\n",
    "    pattern = r'(\\d{4}-\\d{2}-\\d{2}[_T]\\d{2}[-:]\\d{2}[-:]\\d{2})'\n",
    "    match = re.search(pattern, filename)\n",
    "    \n",
    "    if match:\n",
    "        # Convert matched string to datetime\n",
    "        dt_str = match.group(1).replace('_', 'T').replace('-', ':')\n",
    "        return datetime.datetime.fromisoformat(dt_str)\n",
    "    \n",
    "    # Fallback: use file modification time if pattern doesn't match\n",
    "    file_stat = os.stat(filename)\n",
    "    return datetime.datetime.fromtimestamp(file_stat.st_mtime)\n",
    "\n",
    "def process_file(file_path):\n",
    "    \"\"\"Process a single file to extract timestamp and calculate brightness.\"\"\"\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as hf:\n",
    "            # Get data and calculate brightness\n",
    "            data = hf['data'][:]\n",
    "            brightness = np.nansum(data)\n",
    "            \n",
    "            # Try to get timestamp from file metadata if available\n",
    "            timestamp = None\n",
    "            if 'timestamp' in hf.attrs:\n",
    "                timestamp = hf.attrs['timestamp']\n",
    "            else:\n",
    "                # Extract from filename\n",
    "                timestamp = extract_timestamp(file_path)\n",
    "                \n",
    "            return timestamp, brightness, file_path.name\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Calculate total brightness for each file in parallel\n",
    "print(\"Calculating total brightness for each file in parallel...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Define number of workers based on CPU cores\n",
    "num_workers = os.cpu_count() - 1  # Leave one core free\n",
    "if num_workers < 1:\n",
    "    num_workers = 1\n",
    "\n",
    "results = []\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Submit all tasks\n",
    "    futures = {executor.submit(process_file, file_path): file_path for file_path in h5_files}\n",
    "    \n",
    "    # Process results as they complete\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "        file_path = futures[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Parallel processing completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Convert results to a DataFrame for easier manipulation\n",
    "brightness_df = pd.DataFrame(results, columns=['timestamp', 'brightness', 'filename'])\n",
    "brightness_df = brightness_df.sort_values('timestamp')\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = \"data/processed/total_brightness_timeseries.csv\"\n",
    "brightness_df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved time series data to {csv_path}\")\n",
    "\n",
    "# Also save to numpy format\n",
    "np_path = \"data/processed/total_brightness_timeseries.npz\"\n",
    "np.savez(np_path, \n",
    "         timestamps=brightness_df['timestamp'].astype(np.datetime64).values,\n",
    "         brightness=brightness_df['brightness'].values,\n",
    "         filenames=brightness_df['filename'].values)\n",
    "print(f\"Saved numpy array to {np_path}\")\n",
    "\n",
    "# Display basic statistics\n",
    "brightness_array = brightness_df['brightness'].values\n",
    "\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(f\"Total number of files processed: {len(brightness_df)}\")\n",
    "print(f\"Mean total brightness: {np.mean(brightness_array):.2e}\")\n",
    "print(f\"Standard deviation: {np.std(brightness_array):.2e}\")\n",
    "print(f\"Min: {np.min(brightness_array):.2e}\")\n",
    "print(f\"Max: {np.max(brightness_array):.2e}\")\n",
    "\n",
    "# Plot time series data\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(brightness_df['timestamp'], brightness_df['brightness'])\n",
    "plt.title('Total Brightness Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Total Brightness')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/processed/brightness_timeseries.png')\n",
    "plt.show()\n",
    "\n",
    "# Continue with the sampling stability analysis\n",
    "# (keep your existing code for this part)\n",
    "sample_sizes = [10, 50, 100, 200, 500, 1000, 2000, 5000]\n",
    "if len(brightness_df) < 5000:\n",
    "    # Adjust sample sizes if we have fewer data points\n",
    "    sample_sizes = [s for s in sample_sizes if s <= len(brightness_df)]\n",
    "    if len(sample_sizes) == 0:\n",
    "        sample_sizes = [1, 5, 10, len(brightness_df)//2, len(brightness_df)]\n",
    "\n",
    "num_experiments = 100  # Number of random sampling experiments for each size\n",
    "sampling_results = []\n",
    "\n",
    "for sample_size in tqdm(sample_sizes):\n",
    "    means = []\n",
    "    stds = []\n",
    "    \n",
    "    for _ in range(num_experiments):\n",
    "        if sample_size < len(brightness_array):\n",
    "            sample = np.random.choice(brightness_array, size=sample_size, replace=False)\n",
    "        else:\n",
    "            sample = brightness_array\n",
    "            \n",
    "        means.append(np.mean(sample))\n",
    "        stds.append(np.std(sample))\n",
    "    \n",
    "    sampling_results.append({\n",
    "        'sample_size': sample_size,\n",
    "        'mean_of_means': np.mean(means),\n",
    "        'std_of_means': np.std(means),\n",
    "        'mean_of_stds': np.mean(stds)\n",
    "    })\n",
    "\n",
    "# Rest of your plotting code as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化方法：\n",
    "- 随机化计算有效数据点数的平均值 $n$\n",
    "- 计算标准化系数：$m_f=1$ , $sigma_f=sigma/m$ （考虑到 nolimbdark 数据为相对值，用 m 代替平静太阳的值）\n",
    "- 选取 $4 sigma$ 内结果映射到 $[0,255]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\study-and-research\\sunspot-with-sora\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MetaDict([('simple': 'True')\n",
       "('bitpix': '16')\n",
       "('naxis': '2')\n",
       "('naxis1': '4096')\n",
       "('naxis2': '4096')\n",
       "('blank': '-32768')\n",
       "('bzero': '97304.0')\n",
       "('bscale': '3.0')\n",
       "('checksum': 'mFd8nFZ6mFb6mFZ6')\n",
       "('datasum': '1599264056')\n",
       "('date': '2020-06-05T20:22:05.000')\n",
       "('date-obs': '2020-05-31T23:58:45.000')\n",
       "('telescop': 'SDO/HMI')\n",
       "('instrume': 'HMI_COMBINED')\n",
       "('wavelnth': '6173.0')\n",
       "('camera': '3')\n",
       "('bunit': 'DN/s')\n",
       "('origin': 'SDO/JSOC-SDP')\n",
       "('content': 'CONTINUUM INTENSITY')\n",
       "('quality': '0')\n",
       "('quallev1': '0')\n",
       "('history': 'Polynomial Coefficients used for Doppler velocity correction: 2.114895e+\n",
       "02 6.663229e-03 -1.029628e-05 -5.712074e-10')\n",
       "('comment': 'FITS (Flexible Image Transport System) format is defined in 'Astronomy\n",
       "  and Astrophysics', volume 376, page 359; bibcode: 2001A&A...376..359H\n",
       "De-rotation: ON; Un-distortion: ON; Re-centering: ON; Re-sizing: OFF; co\n",
       "rrection for cosmic-ray hits; correction front/side intensity implemente\n",
       "d for mod L; RSUNerr=5.0 pixels; dpath=/home/jsoc/cvs/Development/JSOC/p\n",
       "roj/lev1.5_hmi/apps/; linearity=1 with coefficients updated on 2014/01/1\n",
       "5; smooth=1; propagate eclipse bit from level 1; use of larger crop radi\n",
       "us look-up tables\n",
       "  This FITS file may contain long string keyword values that are\n",
       "  continued over multiple keywords.  The HEASARC convention uses the &\n",
       "  character at the end of each substring which is then continued\n",
       "  on the next keyword which has the name CONTINUE.')\n",
       "('bld_vers': '-903')\n",
       "('hcamid': '2')\n",
       "('source': 'hmi.lev1[:#264077243,#264077195,#264077147,#264077099,#264077051,#264077003,#264076955,#264076907,#264077291,#264077351,#264077387,#264077435,#264077495,#264077531,#264077244,#264077196,#264077148,#264077100,#264077052,#264077004,#264076956,#264076908,#264077292,#264077352,#264077388,#264077436,#264077496,#264077532,#264077245,#264077197,#264077149,#264077101,#264077053,#264077005,#264076957,#264076909,#264077293,#264077353,#264077389,#264077437,#264077497,#264077533,#264077246,#264077198,#264077150,#264077102,#264077054,#264077006,#264076958,#264076910,#264077294,#264077354,#264077390,#264077438,#264077498,#264077534,#264077267,#264077219,#264077171,#264077123,#264077075,#264077027,#264076967,#264076931,#264077315,#264077375,#264077411,#264077459,#264077507,#264077555,#264077268,#264077220,#264077172,#264077124,#264077076,#264077028,#264076968,#264076932,#264077316,#264077376,#264077412,#264077460,#264077508,#264077556,#264077269,#264077221,#264077173,#264077125,#264077077,#264077029,#264076969,#264076933,#264077317,#264077377,#264077413,#264077461,#264077509,#264077557,#264077270,#264077222,#264077174,#264077126,#264077078,#264077030,#264076970,#264076934,#264077318,#264077378,#264077414,#264077462,#264077510,#264077558,#264077251,#264077203,#264077155,#264077107,#264077059,#264077011,#264076963,#264076915,#264077299,#264077359,#264077395,#264077443,#264077503,#264077539,#264077252,#264077204,#264077156,#264077108,#264077060,#264077012,#264076964,#264076916,#264077300,#264077360,#264077396,#264077444,#264077504,#264077540,#264077253,#264077205,#264077157,#264077109,#264077061,#264077013,#264076965,#264076917,#264077301,#264077361,#264077397,#264077445,#264077505,#264077541,#264077254,#264077206,#264077158,#264077110,#264077062,#264077014,#264076966,#264076918,#264077302,#264077362,#264077398,#264077446,#264077506,#264077542,#264077275,#264077227,#264077179,#264077131,#264077083,#264077035,#264076975,#264076939,#264077323,#264077383,#264077419,#264077467,#264077515,#264077563,#264077276,#264077228,#264077180,#264077132,#264077084,#264077036,#264076976,#264076940,#264077324,#264077384,#264077420,#264077468,#264077516,#264077564,#264077277,#264077229,#264077181,#264077133,#264077085,#264077037,#264076977,#264076941,#264077325,#264077385,#264077421,#264077469,#264077517,#264077565,#264077278,#264077230,#264077182,#264077134,#264077086,#264077038,#264076978,#264076942,#264077326,#264077386,#264077422,#264077470,#264077518,#264077566,#264077279,#264077207,#264077159,#264077111,#264077063,#264077015,#264076979,#264076919,#264077303,#264077327,#264077399,#264077447,#264077483,#264077543,#264077280,#264077208,#264077160,#264077112,#264077064,#264077016,#264076980,#264076920,#264077304,#264077328,#264077400,#264077448,#264077484,#264077544,#264077281,#264077209,#264077161,#264077113,#264077065,#264077017,#264076981,#264076921,#264077305,#264077329,#264077401,#264077449,#264077485,#264077545,#264077282,#264077210,#264077162,#264077114,#264077066,#264077018,#264076982,#264076922,#264077306,#264077330,#264077402,#264077450,#264077486,#264077546,#264077255,#264077231,#264077183,#264077135,#264077087,#264077039,#264076991,#264076943,#264077339,#264077363,#264077423,#264077471,#264077519,#264077567,#264077256,#264077232,#264077184,#264077136,#264077088,#264077040,#264076992,#264076944,#264077340,#264077364,#264077424,#264077472,#264077520,#264077568,#264077257,#264077233,#264077185,#264077137,#264077089,#264077041,#264076993,#264076945,#264077341,#264077365,#264077425,#264077473,#264077521,#264077569,#264077258,#264077234,#264077186,#264077138,#264077090,#264077042,#264076994,#264076946,#264077342,#264077366,#264077426,#264077474,#264077522,#264077570,#264077235,#264077187,#264077139,#264077091,#264077043,#264076995,#264076947,#264077259,#264077343,#264077367,#264077427,#264077475,#264077523,#264077571,#264077236,#264077188,#264077140,#264077092,#264077044,#264076996,#264076948,#264077260,#264077344,#264077368,#264077428,#264077476,#264077524,#264077572,#264077237,#264077189,#264077141,#264077093,#264077045,#264076997,#264076949,#264077261,#264077345,#264077369,#264077429,#264077477,#264077525,#264077573,#264077238,#264077190,#264077142,#264077094,#264077046,#264076998,#264076950,#264077262,#264077346,#264077370,#264077430,#264077478,#264077526,#264077574,#264077283,#264077211,#264077163,#264077115,#264077067,#264077019,#264076983,#264076923,#264077307,#264077331,#264077403,#264077451,#264077487,#264077547,#264077284,#264077212,#264077164,#264077116,#264077068,#264077020,#264076984,#264076924,#264077308,#264077332,#264077404,#264077452,#264077488,#264077548,#264077285,#264077213,#264077165,#264077117,#264077069,#264077021,#264076985,#264076925,#264077309,#264077333,#264077405,#264077453,#264077489,#264077549,#264077286,#264077214,#264077166,#264077118,#264077070,#264077022,#264076986,#264076926,#264077310,#264077334,#264077406,#264077454,#264077490,#264077550,#264077239,#264077191,#264077143,#264077095,#264077047,#264076999,#264076951,#264076903,#264077263,#264077347,#264077371,#264077431,#264077479,#264077527,#264077240,#264077192,#264077144,#264077096,#264077048,#264077000,#264076952,#264076904,#264077264,#264077348,#264077372,#264077432,#264077480,#264077528,#264077241,#264077193,#264077145,#264077097,#264077049,#264077001,#264076953,#264076905,#264077265,#264077349,#264077373,#264077433,#264077481,#264077529,#264077242,#264077194,#264077146,#264077098,#264077050,#264077002,#264076954,#264076906,#264077266,#264077350,#264077374,#264077434,#264077482,#264077530,#264077287,#264077215,#264077167,#264077119,#264077071,#264077023,#264076987,#264076927,#264077311,#264077335,#264077407,#264077455,#264077491,#264077551,#264077288,#264077216,#264077168,#264077120,#264077072,#264077024,#264076988,#264076928,#264077312,#264077336,#264077408,#264077456,#264077492,#264077552,#264077289,#264077217,#264077169,#264077121,#264077073,#264077025,#264076989,#264076929,#264077313,#264077337,#264077409,#264077457,#264077493,#264077553,#264077290,#264077218,#264077170,#264077122,#264077074,#264077026,#264076990,#264076930,#264077314,#264077338,#264077410,#264077458,#264077494,#264077554,#264077247,#264077199,#264077151,#264077103,#264077055,#264077007,#264076959,#264076911,#264077295,#264077355,#264077391,#264077439,#264077499,#264077535,#264077248,#264077200,#264077152,#264077104,#264077056,#264077008,#264076960,#264076912,#264077296,#264077356,#264077392,#264077440,#264077500,#264077536,#264077249,#264077201,#264077153,#264077105,#264077057,#264077009,#264076961,#264076913,#264077297,#264077357,#264077393,#264077441,#264077501,#264077537,#264077250,#264077202,#264077154,#264077106,#264077058,#264077010,#264076962,#264076914,#264077298,#264077358,#264077394,#264077442,#264077502,#264077538,#264077271,#264077223,#264077175,#264077127,#264077079,#264077031,#264076971,#264076935,#264077319,#264077379,#264077415,#264077463,#264077511,#264077559,#264077272,#264077224,#264077176,#264077128,#264077080,#264077032,#264076972,#264076936,#264077320,#264077380,#264077416,#264077464,#264077512,#264077560,#264077273,#264077225,#264077177,#264077129,#264077081,#264077033,#264076973,#264076937,#264077321,#264077381,#264077417,#264077465,#264077513,#264077561,#264077274,#264077226,#264077178,#264077130,#264077082,#264077034,#264076974,#264076938,#264077322,#264077382,#264077418,#264077466,#264077514,#264077562]')\n",
       "('totvals': '12164109')\n",
       "('datavals': '12164109')\n",
       "('missvals': '0')\n",
       "('satvals': '7577')\n",
       "('datamin2': '160.670273')\n",
       "('datamax2': '56228.5352')\n",
       "('datamed2': '41985.6953')\n",
       "('datamea2': '37694.3086')\n",
       "('datarms2': '13401.5547')\n",
       "('dataske2': '-1.80662072')\n",
       "('datakur2': '2.51948023')\n",
       "('datamin': '22824.3027')\n",
       "('datamax': '56228.5352')\n",
       "('datamedn': '43071.0156')\n",
       "('datamean': '41754.1367')\n",
       "('datarms': '6368.96338')\n",
       "('dataskew': '-0.69970113')\n",
       "('datakurt': '-0.250334561')\n",
       "('ctype1': 'HPLN-TAN')\n",
       "('ctype2': 'HPLT-TAN')\n",
       "('crpix1': '2038.13013')\n",
       "('crpix2': '2052.37109')\n",
       "('crval1': '0.0')\n",
       "('crval2': '0.0')\n",
       "('cdelt1': '0.504028022')\n",
       "('cdelt2': '0.504028022')\n",
       "('cunit1': 'arcsec')\n",
       "('cunit2': 'arcsec')\n",
       "('crota2': '180.013504')\n",
       "('crder1': '0.0')\n",
       "('crder2': '0.0')\n",
       "('csyser1': 'None')\n",
       "('csyser2': 'None')\n",
       "('wcsname': 'Helioprojective-cartesian')\n",
       "('dsun_obs': '151687120434.931')\n",
       "('dsun_ref': '149597870691.0')\n",
       "('rsun_ref': '696000000.0')\n",
       "('crln_obs': '226.060074')\n",
       "('crlt_obs': '-0.637910545')\n",
       "('car_rot': '2231')\n",
       "('obs_vr': '2247.695184831079')\n",
       "('obs_vw': '28167.34944872577')\n",
       "('obs_vn': '5820.258964580935')\n",
       "('rsun_obs': '946.4271240234375')\n",
       "('t_obs': '2020.06.01_00:00:06.969_TAI')\n",
       "('t_rec': '2020.06.01_00:00:00.000_TAI')\n",
       "('trecepoc': '1993.01.01_00:00:00.000_TAI')\n",
       "('trecstep': '720.0')\n",
       "('trecunit': 'secs')\n",
       "('cadence': '720.0')\n",
       "('datasign': '1')\n",
       "('hflid': '1022')\n",
       "('hcftid': '10')\n",
       "('qlook': '0')\n",
       "('cal_fsn': '155202778')\n",
       "('lutquery': 'hmi.lookup_corrected_expanded[155202778][][2][38][48][0][79][6]')\n",
       "('tsel': '22.2836781')\n",
       "('tfront': '35.6602325')\n",
       "('tintnum': '672')\n",
       "('sintnum': '10')\n",
       "('distcoef': '/home/jsoc/cvs/Development/JSOC/proj/lev1.5_hmi/apps//../libs/lev15/')\n",
       "('rotcoef': '/home/jsoc/cvs/Development/JSOC/proj/lev1.5_hmi/apps//../libs/lev15/')\n",
       "('odicoeff': '6')\n",
       "('orocoeff': '4')\n",
       "('polcalm': '1')\n",
       "('codever0': '$Id: HMI_IQUV_averaging.c,v 1.57 2018/08/31 22:42:51 phil Exp $')\n",
       "('codever1': '$Id: interpol_code.c,v 1.6 2017/08/31 22:17:13 arta Exp $')\n",
       "('codever2': '$Id: interpol_code.c,v 1.6 2017/08/31 22:17:13 arta Exp $')\n",
       "('codever3': '$Id: polcal.c,v 1.8 2016/10/03 19:11:21 arta Exp $')\n",
       "('calver64': '270610')\n",
       "('recnum': '668634')\n",
       "('drms_id': 'hmi.Ic_720s:668634:continuum')\n",
       "('primaryk': 'T_REC, CAMERA')\n",
       "('license': 'LICENSE')\n",
       "('headsum': 'QIhaRFgUQFgaQFgU')\n",
       "('longstrn': 'OGIP 1.0')\n",
       "('keycomments': '{'SIMPLE': 'file does conform to FITS standard', 'BITPIX': 'data type of original image', 'NAXIS': 'dimension of original image', 'NAXIS1': 'length of original image axis', 'NAXIS2': 'length of original image axis', 'CHECKSUM': 'HDU checksum updated 2024-03-16T16:29:01', 'DATASUM': 'data unit checksum updated 2020-06-05T20:22:33', 'DATE': '[ISO] HDU creation date', 'DATE-OBS': '[ISO] Observation date {DATE__OBS}', 'TELESCOP': 'Telescope', 'INSTRUME': 'For HMI: HMI_SIDE1, HMI_FRONT2, or HMI_COMBINED', 'WAVELNTH': '[angstrom] Wavelength', 'CAMERA': 'Camera', 'BUNIT': 'Physical Units', 'ORIGIN': 'Origin', 'CONTENT': 'Content', 'QUALITY': 'Level 1.5 quality', 'QUALLEV1': 'Level 1 quality', 'BLD_VERS': 'Code release build number of program that creat', 'HCAMID': 'HMI_SEQ_ID_EXP_PATH', 'SOURCE': 'level 1 filtergrams used to produce the observa', 'TOTVALS': 'Total values', 'DATAVALS': 'Data values', 'MISSVALS': 'Missing values', 'SATVALS': 'Saturated values', 'DATAMIN2': '[DN/s] Minimum value 2', 'DATAMAX2': '[DN/s] Maximum value 2', 'DATAMED2': '[DN/s] Median value 2', 'DATAMEA2': '[DN/s] Mean value 2', 'DATARMS2': '[DN/s] RMS 2', 'DATASKE2': '[DN/s] Skewness 2', 'DATAKUR2': '[DN/s] Kurtosis 2', 'DATAMIN': '[DN/s] Minimum value', 'DATAMAX': '[DN/s] Maximum value', 'DATAMEDN': '[DN/s] Median value', 'DATAMEAN': '[DN/s] Mean value from pixels within 99% of sol', 'DATARMS': '[DN/s] RMS', 'DATASKEW': '[DN/s] Skewness', 'DATAKURT': '[DN/s] Kurtosis', 'CTYPE1': 'CTYPE1: HPLN', 'CTYPE2': 'CTYPE2: HPLT', 'CRPIX1': '[pixel] CRPIX1: location of the Sun center in C', 'CRPIX2': '[pixel] CRPIX2: location of the Sun center in C', 'CRVAL1': '[arcsec] CRVAL1: x origin', 'CRVAL2': '[arcsec] CRVAL2: y origin', 'CDELT1': '[arcsec/pixel] image scale in the x direction', 'CDELT2': '[arcsec/pixel] image scale in the y direction', 'CUNIT1': '[arcsec] CUNIT1: arcsec', 'CUNIT2': '[arcsec] CUNIT2: arcsec', 'CROTA2': '[deg] CROTA2: INST_ROT + SAT_ROT', 'CRDER1': '[arcsec] CRDER1: estimate of random error in co', 'CRDER2': '[arcsec] CRDER2: estimate of random error in co', 'CSYSER1': '[arcsec] (MISSING) CSYSER1: estimate of systema', 'CSYSER2': '[arcsec] (MISSING) CSYSER2: estimate of systema', 'WCSNAME': 'WCS system name', 'DSUN_OBS': '[m] Distance from SDO to Sun center.', 'DSUN_REF': '[m] Astronomical Unit', 'RSUN_REF': '[m] Reference radius of the Sun: 696,000,000.0', 'CRLN_OBS': '[deg] Carrington longitude of the observer', 'CRLT_OBS': '[deg] Carrington latitude of the observer', 'CAR_ROT': 'Carrington rotation number of CRLN_OBS', 'OBS_VR': '[m/s] velocity of the observer in radial direct', 'OBS_VW': '[m/s] velocity of the observer solar', 'OBS_VN': '[m/s] velocity of the observer solar', 'RSUN_OBS': '[arcsec] angular radius of Sun. Corresponds to', 'T_OBS': '[TAI] nominal time', 'T_REC': '[TAI] Slot time', 'TRECEPOC': '[TAI] Time of origin {T_REC_epoch}', 'TRECSTEP': '[seconds] ts_eq step {T_REC_step}', 'TRECUNIT': 'ts_eq unit {T_REC_unit}', 'CADENCE': '[seconds] repetition interval', 'DATASIGN': 'DATASIGN: sign of observable quantity wrt Sun c', 'HFLID': 'HMI_SEQ_ID_FRAMELIST', 'HCFTID': 'HMI_SEQ_ID_FOCUS', 'QLOOK': 'QLOOK: 0=final data, 1=quick', 'CAL_FSN': 'FSN of the look', 'LUTQUERY': 'qu', 'TSEL': '[degree Celsius] temperature keyword for polari', 'TFRONT': '[degree Celsius] temperature keyword for polari', 'TINTNUM': 'number of points used for the temporal averagin', 'SINTNUM': 'number of points used for the spatial interpola', 'ODICOEFF': 'order of the distortion', 'OROCOEFF': 'order of the differential', 'POLCALM': 'method used by the polarization calibration sub', 'CODEVER0': 've', 'CODEVER1': 'version', 'CODEVER2': 'version', 'CODEVER3': 'version of the', 'CALVER64': 'Calibration Version', 'RECNUM': 'Recnum', 'DRMS_ID': 'DRMS ID', 'PRIMARYK': 'DRMS primary key', 'LICENSE': 'CC0 1.0', 'HEADSUM': 'Keyword checksum', 'LONGSTRN': 'The HEASARC Long String Convention may be used.'}')\n",
       "('waveunit': 'angstrom')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import astropy.units as u\n",
    "import sunpy.map\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%cd \"E:/study-and-research/sunspot-with-sora\"\n",
    "data_in = sunpy.map.Map(\n",
    "    r\"data\\origin\\flare_Ic_nolimbdark_720s\\hmi.ic_nolimbdark_720s.20240222_200000_TAI.3.continuum.fits\"\n",
    ")\n",
    "data_in2 = sunpy.map.Map(r\"data\\origin\\Ic_720s\\hmi.ic_720s.20200601_000000_TAI.3.continuum.fits\")\n",
    "\n",
    "np.nanmin(data_in.data)\n",
    "\n",
    "data_in2.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: 验证 DN/s 是否服从平方反比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downsample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\study-and-research\\sunspot-with-sora\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "%cd \"E:\\study-and-research\\sunspot-with-sora\"\n",
    "# Load image\n",
    "image = Image.open(r\"data\\processed\\figure\\figure-origin\\hmi.ic_nolimbdark_720s.20211101_000000_TAI.3.continuum_nd.png\")\n",
    "\n",
    "# Resize using Lanczos\n",
    "resized_image = image.resize((960, 960), Image.LANCZOS)\n",
    "\n",
    "# Save or show the result\n",
    "resized_image.save(r\"data\\processed\\figure\\figure-downsample\\hmi_ic_resized.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用滑动窗口形式构造 dataset\n",
    "\n",
    "TODO 实验不同窗口大小与窗口间隔的影响\n",
    "\n",
    "初步采用：\n",
    "窗口大小：16（~1/4太阳周）\n",
    "间隔：12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\study-and-research\\sunspot-with-sora\n"
     ]
    }
   ],
   "source": [
    "import astropy.units as u\n",
    "import sunpy.map\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%cd \"E:\\study-and-research\\sunspot-with-sora\"\n",
    "data_in = sunpy.map.Map(\n",
    "    \"data\\origin\\Ic_nolimbdark_720s\\hmi.ic_nolimbdark_720s.20211101_000000_TAI.3.continuum.fits\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 4096)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DN/s'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in.meta.get('BUNIT')\n",
    "data_in_2.meta.get('BUNIT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
