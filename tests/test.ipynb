{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View PyTorch Checkpoint File\n",
    "\n",
    "This notebook loads and displays information about the VAE checkpoint file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: ..\\checkpoint\\vae_epoch_5.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the checkpoint file\n",
    "checkpoint_path = Path('../checkpoint/vae_epoch_5.pt')\n",
    "\n",
    "# Check if file exists\n",
    "if not checkpoint_path.exists():\n",
    "    print(f\"File not found: {checkpoint_path}\")\n",
    "else:\n",
    "    print(f\"Loading checkpoint from: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "    print(\"Checkpoint loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading checkpoint: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint contains the following keys:\n",
      "- epoch\n",
      "- model_state_dict\n",
      "\n",
      "Model state dictionary structure:\n",
      "  encoder.conv_in.conv.weight: torch.Size([128, 3, 3, 3, 3])\n",
      "  encoder.conv_in.conv.bias: torch.Size([128])\n",
      "  encoder.down.0.block.0.norm1.weight: torch.Size([128])\n",
      "  encoder.down.0.block.0.norm1.bias: torch.Size([128])\n",
      "  encoder.down.0.block.0.conv1.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "  encoder.down.0.block.0.conv1.conv.bias: torch.Size([128])\n",
      "  encoder.down.0.block.0.norm2.weight: torch.Size([128])\n",
      "  encoder.down.0.block.0.norm2.bias: torch.Size([128])\n",
      "  encoder.down.0.block.0.conv2.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "  encoder.down.0.block.0.conv2.conv.bias: torch.Size([128])\n",
      "  encoder.down.0.block.1.norm1.weight: torch.Size([128])\n",
      "  encoder.down.0.block.1.norm1.bias: torch.Size([128])\n",
      "  encoder.down.0.block.1.conv1.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "  encoder.down.0.block.1.conv1.conv.bias: torch.Size([128])\n",
      "  encoder.down.0.block.1.norm2.weight: torch.Size([128])\n",
      "  encoder.down.0.block.1.norm2.bias: torch.Size([128])\n",
      "  encoder.down.0.block.1.conv2.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "  encoder.down.0.block.1.conv2.conv.bias: torch.Size([128])\n",
      "  encoder.down.0.downsample.conv.weight: torch.Size([128, 128, 3, 3])\n",
      "  encoder.down.0.downsample.conv.bias: torch.Size([128])\n",
      "  encoder.down.1.block.0.norm1.weight: torch.Size([128])\n",
      "  encoder.down.1.block.0.norm1.bias: torch.Size([128])\n",
      "  encoder.down.1.block.0.conv1.conv.weight: torch.Size([256, 128, 3, 3, 3])\n",
      "  encoder.down.1.block.0.conv1.conv.bias: torch.Size([256])\n",
      "  encoder.down.1.block.0.norm2.weight: torch.Size([256])\n",
      "  encoder.down.1.block.0.norm2.bias: torch.Size([256])\n",
      "  encoder.down.1.block.0.conv2.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "  encoder.down.1.block.0.conv2.conv.bias: torch.Size([256])\n",
      "  encoder.down.1.block.0.nin_shortcut.conv.weight: torch.Size([256, 128, 1, 1, 1])\n",
      "  encoder.down.1.block.0.nin_shortcut.conv.bias: torch.Size([256])\n",
      "  encoder.down.1.block.1.norm1.weight: torch.Size([256])\n",
      "  encoder.down.1.block.1.norm1.bias: torch.Size([256])\n",
      "  encoder.down.1.block.1.conv1.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "  encoder.down.1.block.1.conv1.conv.bias: torch.Size([256])\n",
      "  encoder.down.1.block.1.norm2.weight: torch.Size([256])\n",
      "  encoder.down.1.block.1.norm2.bias: torch.Size([256])\n",
      "  encoder.down.1.block.1.conv2.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "  encoder.down.1.block.1.conv2.conv.bias: torch.Size([256])\n",
      "  encoder.down.1.downsample.conv.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "  encoder.down.1.downsample.conv.conv.bias: torch.Size([256])\n",
      "  encoder.down.2.block.0.norm1.weight: torch.Size([256])\n",
      "  encoder.down.2.block.0.norm1.bias: torch.Size([256])\n",
      "  encoder.down.2.block.0.conv1.conv.weight: torch.Size([512, 256, 3, 3, 3])\n",
      "  encoder.down.2.block.0.conv1.conv.bias: torch.Size([512])\n",
      "  encoder.down.2.block.0.norm2.weight: torch.Size([512])\n",
      "  encoder.down.2.block.0.norm2.bias: torch.Size([512])\n",
      "  encoder.down.2.block.0.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.down.2.block.0.conv2.conv.bias: torch.Size([512])\n",
      "  encoder.down.2.block.0.nin_shortcut.conv.weight: torch.Size([512, 256, 1, 1, 1])\n",
      "  encoder.down.2.block.0.nin_shortcut.conv.bias: torch.Size([512])\n",
      "  encoder.down.2.block.1.norm1.weight: torch.Size([512])\n",
      "  encoder.down.2.block.1.norm1.bias: torch.Size([512])\n",
      "  encoder.down.2.block.1.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.down.2.block.1.conv1.conv.bias: torch.Size([512])\n",
      "  encoder.down.2.block.1.norm2.weight: torch.Size([512])\n",
      "  encoder.down.2.block.1.norm2.bias: torch.Size([512])\n",
      "  encoder.down.2.block.1.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.down.2.block.1.conv2.conv.bias: torch.Size([512])\n",
      "  encoder.down.2.downsample.conv.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.down.2.downsample.conv.conv.bias: torch.Size([512])\n",
      "  encoder.down.3.block.0.norm1.weight: torch.Size([512])\n",
      "  encoder.down.3.block.0.norm1.bias: torch.Size([512])\n",
      "  encoder.down.3.block.0.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.down.3.block.0.conv1.conv.bias: torch.Size([512])\n",
      "  encoder.down.3.block.0.norm2.weight: torch.Size([512])\n",
      "  encoder.down.3.block.0.norm2.bias: torch.Size([512])\n",
      "  encoder.down.3.block.0.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.down.3.block.0.conv2.conv.bias: torch.Size([512])\n",
      "  encoder.down.3.block.1.norm1.weight: torch.Size([512])\n",
      "  encoder.down.3.block.1.norm1.bias: torch.Size([512])\n",
      "  encoder.down.3.block.1.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.down.3.block.1.conv1.conv.bias: torch.Size([512])\n",
      "  encoder.down.3.block.1.norm2.weight: torch.Size([512])\n",
      "  encoder.down.3.block.1.norm2.bias: torch.Size([512])\n",
      "  encoder.down.3.block.1.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.down.3.block.1.conv2.conv.bias: torch.Size([512])\n",
      "  encoder.mid.block_1.norm1.weight: torch.Size([512])\n",
      "  encoder.mid.block_1.norm1.bias: torch.Size([512])\n",
      "  encoder.mid.block_1.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.mid.block_1.conv1.conv.bias: torch.Size([512])\n",
      "  encoder.mid.block_1.norm2.weight: torch.Size([512])\n",
      "  encoder.mid.block_1.norm2.bias: torch.Size([512])\n",
      "  encoder.mid.block_1.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.mid.block_1.conv2.conv.bias: torch.Size([512])\n",
      "  encoder.mid.attn_1.norm.weight: torch.Size([512])\n",
      "  encoder.mid.attn_1.norm.bias: torch.Size([512])\n",
      "  encoder.mid.attn_1.q.conv.weight: torch.Size([512, 512, 1, 1, 1])\n",
      "  encoder.mid.attn_1.q.conv.bias: torch.Size([512])\n",
      "  encoder.mid.attn_1.k.conv.weight: torch.Size([512, 512, 1, 1, 1])\n",
      "  encoder.mid.attn_1.k.conv.bias: torch.Size([512])\n",
      "  encoder.mid.attn_1.v.conv.weight: torch.Size([512, 512, 1, 1, 1])\n",
      "  encoder.mid.attn_1.v.conv.bias: torch.Size([512])\n",
      "  encoder.mid.attn_1.proj_out.conv.weight: torch.Size([512, 512, 1, 1, 1])\n",
      "  encoder.mid.attn_1.proj_out.conv.bias: torch.Size([512])\n",
      "  encoder.mid.block_2.norm1.weight: torch.Size([512])\n",
      "  encoder.mid.block_2.norm1.bias: torch.Size([512])\n",
      "  encoder.mid.block_2.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.mid.block_2.conv1.conv.bias: torch.Size([512])\n",
      "  encoder.mid.block_2.norm2.weight: torch.Size([512])\n",
      "  encoder.mid.block_2.norm2.bias: torch.Size([512])\n",
      "  encoder.mid.block_2.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  encoder.mid.block_2.conv2.conv.bias: torch.Size([512])\n",
      "  encoder.norm_out.weight: torch.Size([512])\n",
      "  encoder.norm_out.bias: torch.Size([512])\n",
      "  encoder.conv_out.conv.weight: torch.Size([32, 512, 3, 3, 3])\n",
      "  encoder.conv_out.conv.bias: torch.Size([32])\n",
      "  decoder.conv_in.conv.weight: torch.Size([512, 16, 3, 3, 3])\n",
      "  decoder.conv_in.conv.bias: torch.Size([512])\n",
      "  decoder.mid.block_1.norm1.weight: torch.Size([512])\n",
      "  decoder.mid.block_1.norm1.bias: torch.Size([512])\n",
      "  decoder.mid.block_1.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.mid.block_1.conv1.conv.bias: torch.Size([512])\n",
      "  decoder.mid.block_1.norm2.weight: torch.Size([512])\n",
      "  decoder.mid.block_1.norm2.bias: torch.Size([512])\n",
      "  decoder.mid.block_1.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.mid.block_1.conv2.conv.bias: torch.Size([512])\n",
      "  decoder.mid.attn_1.norm.weight: torch.Size([512])\n",
      "  decoder.mid.attn_1.norm.bias: torch.Size([512])\n",
      "  decoder.mid.attn_1.q.conv.weight: torch.Size([512, 512, 1, 1, 1])\n",
      "  decoder.mid.attn_1.q.conv.bias: torch.Size([512])\n",
      "  decoder.mid.attn_1.k.conv.weight: torch.Size([512, 512, 1, 1, 1])\n",
      "  decoder.mid.attn_1.k.conv.bias: torch.Size([512])\n",
      "  decoder.mid.attn_1.v.conv.weight: torch.Size([512, 512, 1, 1, 1])\n",
      "  decoder.mid.attn_1.v.conv.bias: torch.Size([512])\n",
      "  decoder.mid.attn_1.proj_out.conv.weight: torch.Size([512, 512, 1, 1, 1])\n",
      "  decoder.mid.attn_1.proj_out.conv.bias: torch.Size([512])\n",
      "  decoder.mid.block_2.norm1.weight: torch.Size([512])\n",
      "  decoder.mid.block_2.norm1.bias: torch.Size([512])\n",
      "  decoder.mid.block_2.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.mid.block_2.conv1.conv.bias: torch.Size([512])\n",
      "  decoder.mid.block_2.norm2.weight: torch.Size([512])\n",
      "  decoder.mid.block_2.norm2.bias: torch.Size([512])\n",
      "  decoder.mid.block_2.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.mid.block_2.conv2.conv.bias: torch.Size([512])\n",
      "  decoder.up.0.block.0.norm1.weight: torch.Size([256])\n",
      "  decoder.up.0.block.0.norm1.bias: torch.Size([256])\n",
      "  decoder.up.0.block.0.conv1.conv.weight: torch.Size([128, 256, 3, 3, 3])\n",
      "  decoder.up.0.block.0.conv1.conv.bias: torch.Size([128])\n",
      "  decoder.up.0.block.0.norm2.weight: torch.Size([128])\n",
      "  decoder.up.0.block.0.norm2.bias: torch.Size([128])\n",
      "  decoder.up.0.block.0.conv2.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "  decoder.up.0.block.0.conv2.conv.bias: torch.Size([128])\n",
      "  decoder.up.0.block.0.nin_shortcut.conv.weight: torch.Size([128, 256, 1, 1, 1])\n",
      "  decoder.up.0.block.0.nin_shortcut.conv.bias: torch.Size([128])\n",
      "  decoder.up.0.block.1.norm1.weight: torch.Size([128])\n",
      "  decoder.up.0.block.1.norm1.bias: torch.Size([128])\n",
      "  decoder.up.0.block.1.conv1.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "  decoder.up.0.block.1.conv1.conv.bias: torch.Size([128])\n",
      "  decoder.up.0.block.1.norm2.weight: torch.Size([128])\n",
      "  decoder.up.0.block.1.norm2.bias: torch.Size([128])\n",
      "  decoder.up.0.block.1.conv2.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "  decoder.up.0.block.1.conv2.conv.bias: torch.Size([128])\n",
      "  decoder.up.0.block.2.norm1.weight: torch.Size([128])\n",
      "  decoder.up.0.block.2.norm1.bias: torch.Size([128])\n",
      "  decoder.up.0.block.2.conv1.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "  decoder.up.0.block.2.conv1.conv.bias: torch.Size([128])\n",
      "  decoder.up.0.block.2.norm2.weight: torch.Size([128])\n",
      "  decoder.up.0.block.2.norm2.bias: torch.Size([128])\n",
      "  decoder.up.0.block.2.conv2.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "  decoder.up.0.block.2.conv2.conv.bias: torch.Size([128])\n",
      "  decoder.up.1.block.0.norm1.weight: torch.Size([512])\n",
      "  decoder.up.1.block.0.norm1.bias: torch.Size([512])\n",
      "  decoder.up.1.block.0.conv1.conv.weight: torch.Size([256, 512, 3, 3, 3])\n",
      "  decoder.up.1.block.0.conv1.conv.bias: torch.Size([256])\n",
      "  decoder.up.1.block.0.norm2.weight: torch.Size([256])\n",
      "  decoder.up.1.block.0.norm2.bias: torch.Size([256])\n",
      "  decoder.up.1.block.0.conv2.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "  decoder.up.1.block.0.conv2.conv.bias: torch.Size([256])\n",
      "  decoder.up.1.block.0.nin_shortcut.conv.weight: torch.Size([256, 512, 1, 1, 1])\n",
      "  decoder.up.1.block.0.nin_shortcut.conv.bias: torch.Size([256])\n",
      "  decoder.up.1.block.1.norm1.weight: torch.Size([256])\n",
      "  decoder.up.1.block.1.norm1.bias: torch.Size([256])\n",
      "  decoder.up.1.block.1.conv1.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "  decoder.up.1.block.1.conv1.conv.bias: torch.Size([256])\n",
      "  decoder.up.1.block.1.norm2.weight: torch.Size([256])\n",
      "  decoder.up.1.block.1.norm2.bias: torch.Size([256])\n",
      "  decoder.up.1.block.1.conv2.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "  decoder.up.1.block.1.conv2.conv.bias: torch.Size([256])\n",
      "  decoder.up.1.block.2.norm1.weight: torch.Size([256])\n",
      "  decoder.up.1.block.2.norm1.bias: torch.Size([256])\n",
      "  decoder.up.1.block.2.conv1.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "  decoder.up.1.block.2.conv1.conv.bias: torch.Size([256])\n",
      "  decoder.up.1.block.2.norm2.weight: torch.Size([256])\n",
      "  decoder.up.1.block.2.norm2.bias: torch.Size([256])\n",
      "  decoder.up.1.block.2.conv2.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "  decoder.up.1.block.2.conv2.conv.bias: torch.Size([256])\n",
      "  decoder.up.1.upsample.conv.weight: torch.Size([256, 256, 3, 3])\n",
      "  decoder.up.1.upsample.conv.bias: torch.Size([256])\n",
      "  decoder.up.2.block.0.norm1.weight: torch.Size([512])\n",
      "  decoder.up.2.block.0.norm1.bias: torch.Size([512])\n",
      "  decoder.up.2.block.0.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.2.block.0.conv1.conv.bias: torch.Size([512])\n",
      "  decoder.up.2.block.0.norm2.weight: torch.Size([512])\n",
      "  decoder.up.2.block.0.norm2.bias: torch.Size([512])\n",
      "  decoder.up.2.block.0.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.2.block.0.conv2.conv.bias: torch.Size([512])\n",
      "  decoder.up.2.block.1.norm1.weight: torch.Size([512])\n",
      "  decoder.up.2.block.1.norm1.bias: torch.Size([512])\n",
      "  decoder.up.2.block.1.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.2.block.1.conv1.conv.bias: torch.Size([512])\n",
      "  decoder.up.2.block.1.norm2.weight: torch.Size([512])\n",
      "  decoder.up.2.block.1.norm2.bias: torch.Size([512])\n",
      "  decoder.up.2.block.1.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.2.block.1.conv2.conv.bias: torch.Size([512])\n",
      "  decoder.up.2.block.2.norm1.weight: torch.Size([512])\n",
      "  decoder.up.2.block.2.norm1.bias: torch.Size([512])\n",
      "  decoder.up.2.block.2.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.2.block.2.conv1.conv.bias: torch.Size([512])\n",
      "  decoder.up.2.block.2.norm2.weight: torch.Size([512])\n",
      "  decoder.up.2.block.2.norm2.bias: torch.Size([512])\n",
      "  decoder.up.2.block.2.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.2.block.2.conv2.conv.bias: torch.Size([512])\n",
      "  decoder.up.2.upsample.conv3d.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.2.upsample.conv3d.conv1.conv.bias: torch.Size([512])\n",
      "  decoder.up.2.upsample.conv3d.norm1.weight: torch.Size([512])\n",
      "  decoder.up.2.upsample.conv3d.norm1.bias: torch.Size([512])\n",
      "  decoder.up.2.upsample.conv3d.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.2.upsample.conv3d.conv2.conv.bias: torch.Size([512])\n",
      "  decoder.up.2.upsample.conv3d.norm2.weight: torch.Size([512])\n",
      "  decoder.up.2.upsample.conv3d.norm2.bias: torch.Size([512])\n",
      "  decoder.up.3.block.0.norm1.weight: torch.Size([512])\n",
      "  decoder.up.3.block.0.norm1.bias: torch.Size([512])\n",
      "  decoder.up.3.block.0.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.3.block.0.conv1.conv.bias: torch.Size([512])\n",
      "  decoder.up.3.block.0.norm2.weight: torch.Size([512])\n",
      "  decoder.up.3.block.0.norm2.bias: torch.Size([512])\n",
      "  decoder.up.3.block.0.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.3.block.0.conv2.conv.bias: torch.Size([512])\n",
      "  decoder.up.3.block.1.norm1.weight: torch.Size([512])\n",
      "  decoder.up.3.block.1.norm1.bias: torch.Size([512])\n",
      "  decoder.up.3.block.1.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.3.block.1.conv1.conv.bias: torch.Size([512])\n",
      "  decoder.up.3.block.1.norm2.weight: torch.Size([512])\n",
      "  decoder.up.3.block.1.norm2.bias: torch.Size([512])\n",
      "  decoder.up.3.block.1.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.3.block.1.conv2.conv.bias: torch.Size([512])\n",
      "  decoder.up.3.block.2.norm1.weight: torch.Size([512])\n",
      "  decoder.up.3.block.2.norm1.bias: torch.Size([512])\n",
      "  decoder.up.3.block.2.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.3.block.2.conv1.conv.bias: torch.Size([512])\n",
      "  decoder.up.3.block.2.norm2.weight: torch.Size([512])\n",
      "  decoder.up.3.block.2.norm2.bias: torch.Size([512])\n",
      "  decoder.up.3.block.2.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.3.block.2.conv2.conv.bias: torch.Size([512])\n",
      "  decoder.up.3.upsample.conv3d.conv1.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.3.upsample.conv3d.conv1.conv.bias: torch.Size([512])\n",
      "  decoder.up.3.upsample.conv3d.norm1.weight: torch.Size([512])\n",
      "  decoder.up.3.upsample.conv3d.norm1.bias: torch.Size([512])\n",
      "  decoder.up.3.upsample.conv3d.conv2.conv.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "  decoder.up.3.upsample.conv3d.conv2.conv.bias: torch.Size([512])\n",
      "  decoder.up.3.upsample.conv3d.norm2.weight: torch.Size([512])\n",
      "  decoder.up.3.upsample.conv3d.norm2.bias: torch.Size([512])\n",
      "  decoder.norm_out.weight: torch.Size([128])\n",
      "  decoder.norm_out.bias: torch.Size([128])\n",
      "  decoder.conv_out.weight: torch.Size([3, 128, 3, 3, 3])\n",
      "  decoder.conv_out.bias: torch.Size([3])\n",
      "- optimizer_state_dict\n",
      "\n",
      "Model state dictionary structure:\n",
      "  state: <class 'dict'>\n",
      "  param_groups: <class 'list'>\n",
      "- loss\n",
      "- scheduler_state_dict\n",
      "\n",
      "Model state dictionary structure:\n",
      "  factor: <class 'float'>\n",
      "  min_lrs: <class 'list'>\n",
      "  patience: <class 'int'>\n",
      "  verbose: <class 'bool'>\n",
      "  cooldown: <class 'int'>\n",
      "  cooldown_counter: <class 'int'>\n",
      "  mode: <class 'str'>\n",
      "  threshold: <class 'float'>\n",
      "  threshold_mode: <class 'str'>\n",
      "  best: <class 'float'>\n",
      "  num_bad_epochs: <class 'int'>\n",
      "  mode_worse: <class 'float'>\n",
      "  eps: <class 'float'>\n",
      "  last_epoch: <class 'int'>\n",
      "  _last_lr: <class 'list'>\n",
      "- scaler_state_dict\n",
      "\n",
      "Model state dictionary structure:\n",
      "  scale: <class 'float'>\n",
      "  growth_factor: <class 'float'>\n",
      "  backoff_factor: <class 'float'>\n",
      "  growth_interval: <class 'int'>\n",
      "  _growth_tracker: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Display the checkpoint structure\n",
    "def explore_checkpoint(checkpoint):\n",
    "    if isinstance(checkpoint, dict):\n",
    "        print(\"Checkpoint contains the following keys:\")\n",
    "        for key in checkpoint:\n",
    "            print(f\"- {key}\")\n",
    "            \n",
    "            # If it's a state_dict, show its structure\n",
    "            if key == 'state_dict' or key == 'model_state_dict' or 'state_dict' in key:\n",
    "                print(\"\\nModel state dictionary structure:\")\n",
    "                for param_name, param in checkpoint[key].items():\n",
    "                    if hasattr(param, 'shape'):\n",
    "                        print(f\"  {param_name}: {param.shape}\")\n",
    "                    else:\n",
    "                        print(f\"  {param_name}: {type(param)}\")\n",
    "    else:\n",
    "        print(f\"Checkpoint is not a dictionary. Type: {type(checkpoint)}\")\n",
    "\n",
    "# Run the exploration function\n",
    "if 'checkpoint' in locals():\n",
    "    explore_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional detailed exploration of specific parts (if needed)\n",
    "# For example, if you want to see specific model parameters\n",
    "\n",
    "if 'checkpoint' in locals():\n",
    "    # Extract model parameters if they exist\n",
    "    if isinstance(checkpoint, dict):\n",
    "        # Try common state dict keys\n",
    "        state_dict_key = None\n",
    "        for key in ['state_dict', 'model_state_dict', 'model']:\n",
    "            if key in checkpoint:\n",
    "                state_dict_key = key\n",
    "                break\n",
    "                \n",
    "        if state_dict_key:\n",
    "            print(f\"First few parameters from '{state_dict_key}':\")\n",
    "            for i, (name, param) in enumerate(list(checkpoint[state_dict_key].items())[:5]):\n",
    "                if hasattr(param, 'shape'):\n",
    "                    print(f\"Parameter {i}: {name}, Shape: {param.shape}\")\n",
    "                    # Print a sample of values from the tensor\n",
    "                    flat_tensor = param.flatten()\n",
    "                    if len(flat_tensor) > 0:\n",
    "                        sample_size = min(5, len(flat_tensor))\n",
    "                        print(f\"Sample values: {flat_tensor[:sample_size]}\")\n",
    "                    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
